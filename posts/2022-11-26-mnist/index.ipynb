{
 "cells": [
  {
   "cell_type": "raw",
   "id": "87c9bb48",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"MNIST, the 'Hello World' of Computer Vision\"\n",
    "author: \"Christian Wittmann\"\n",
    "date: \"2022-11-26\"\n",
    "categories: [kaggle, mnist, fast.ai, vision]\n",
    "image: \"mnist-digits.png\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c920988-ec10-4855-ba64-6e1123bac2be",
   "metadata": {},
   "source": [
    "After [Cat vs. Dog](https://chrwittm.github.io/posts/2022-10-03-bear-detector-2022/), this is the next challenge for me in computer vision: Building on [chapter 4](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb) of the book, I challenged myself to implement a model based on the [MNIST](https://en.wikipedia.org/wiki/MNIST_database) dataset, as recommended as further research.\n",
    "\n",
    "This challenge is also available as a [Kaggle competition](https://www.kaggle.com/competitions/digit-recognizer/data), and I found this bit of competitive spirit to add some spice to the project. Additionally, it broadened the spectrum of implementation topics, because training a model is one thing, but using it for meaningful predictions in equally important and also required some effort. Last, but not least, submitting the results was a nice way to check if the results are actually correct. As predicted: _\"This was a significant project and took you quite a bit of time to complete! I needed to do some of my own research to figure out how to overcome some obstacles on the way\"._\n",
    "\n",
    "I took an iterative approach, following a similar path as for working on the [Titanic-Challenge](https://chrwittm.github.io/posts/2022-11-05-kaggle-titanic/):\n",
    "\n",
    "* First, I implemented a [Fast.AI version](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist1-fastai/mnist01-fastai.ipynb) without making a submission to get a feeling of the data and also to get a result quickly. \n",
    "* Afterwards, I made my first submission. This proved to be a challenge, mainly because of the [data format](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist2-kaggle/mnist02-download-and-convert.ipynb) (more below). Only then, I could make the [submission](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist2-kaggle/mnist03-predict-on-converted-image-files.ipynb).\n",
    "* I was not 100% satisfied with my first submission, because the data handling was not very elegant, so I [re-implemented](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist2-kaggle/mnist04-predict-on-csv-file.ipynb) it.\n",
    "* The above steps set me up for the implementation of a [from-scratch version](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist2-kaggle/mnist05-from-scratch.ipynb) in analogy to [chapter 4](https://github.com/fastai/fastbook/blob/master/04_mnist_basics.ipynb) (where in the book there is \"only\" a model for distinguishing 3s and 7s).\n",
    "* Update Nov 28: Just for esthetics: I exchanged the cover image from this blog post. A collection of MNIST digits is nothing revolutionary, but coding the image in [this notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist2-kaggle/mnist06-create-blog-cover-pic.ipynb) was a nice exercise. \n",
    "\n",
    "It was a challenging project, and I learned a lot on the way. Below are some key points and learnings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb93a864",
   "metadata": {},
   "source": [
    "## The Fast.AI version without a submission\n",
    "\n",
    "By now this is pretty straight-forward for me. I just copy&pasted a few lines of code to do the training, and I was able to create a decent model very quickly in [this notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist1-fastai/mnist01-fastai.ipynb).\n",
    "\n",
    "The catch with this version is, however, that it is not ready for the mass data load: 28.000 predictions need to be done in the competition - something which I addressed in my second iteration.\n",
    "\n",
    "Additionally, I found it interesting that the MNIST dataset was already pushing the limits of my laptop: The training time of about 40 minutes was ok, but it is already quite a burden if it needs to be done multiple times. Moving the learning to [Paperspace](https://console.paperspace.com), training on a free GPU, was 10x faster (no surprise). Since I like to still have everything locally, it is quite convenient moving files back and forth via git, also for the `.pkl`-files. This way the training can be done with GPU, and the inference can be done locally. Interestingly, in all my other notebooks, local performance was not an issue. (But I expect that to change in future other projects)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee42aef1",
   "metadata": {},
   "source": [
    "## Resubmitting: Working with the `csv`-files\n",
    "\n",
    "I found not very elegant to just convert the `csv`-files to `png`-images. That seems convenient, but a bit wasteful. Therefore, I re-implemented the process [this notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist2-kaggle/mnist04-predict-on-csv-file.ipynb).\n",
    "\n",
    "It was surprisingly difficult to convert the data into the right formal in memory so that the learner would accept the image. But finally I was able to convert a `PIL.Image.Image` to `fastai.vision.core.PILImage`. As usual with these things, once it was done, it looks easy.\n",
    "\n",
    "Not surprisingly, but a nice way to verify the result, the submission score was the same:\n",
    "\n",
    "![](https://raw.githubusercontent.com/chrwittm/FastAI2022/main/lesson03/mnist/mnist2-kaggle/sub2-099442.png)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f46d61b",
   "metadata": {},
   "source": [
    "## My first submission\n",
    "\n",
    "When I first downloaded the Kaggle data, I was quite surprised to see that the download did not contain any image files, but just 2 large `csv`-files. Since I only knew how to handle images, I simply converted the data to `png`-images in [this notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist2-kaggle/mnist02-download-and-convert.ipynb).\n",
    "\n",
    "Once that was done, I could take the model trained before in my [first notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist1-fastai/mnist01-fastai.ipynb) to make my first submission. In [this notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist2-kaggle/mnist03-predict-on-converted-image-files.ipynb), I took the converted images and collected the predictions. I found the result of 99.4% quite impressive.\n",
    "\n",
    "![](https://raw.githubusercontent.com/chrwittm/FastAI2022/main/lesson03/mnist/mnist2-kaggle/sub1-099442.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d59eed90",
   "metadata": {},
   "source": [
    "## The from-scratch version\n",
    "\n",
    "Doing it all [from scratch](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist2-kaggle/mnist05-from-scratch.ipynb) was an interesting learning exercise because I think that I already had a good understanding of what needed to be done even before implementing it. But, as it turns out, there is this tremendous difference between thinking that you understood it, and actually implementing it. There is a lot of fine print, and you have to pay attention to the details: Formatting the data, getting it into the correctly shaped tensors, and implementing the gradient descent. Irrespective of what I had learned/understood before, this has greatly deepened and solidified by implementing the MNIST challenge.\n",
    "\n",
    "Some minor mysteries remain, which I also documented in [the notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/mnist/mnist2-kaggle/mnist05-from-scratch.ipynb), if you can guide me how to fix them, please let me know.\n",
    "\n",
    "The finale result of my from scratch-version is not up to the first implementation with resnet18, but I am proud of it for other reasons ;).\n",
    "\n",
    "![](https://raw.githubusercontent.com/chrwittm/FastAI2022/main/lesson03/mnist/mnist2-kaggle/sub3-084817.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d05e88a7",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.4 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9da906b64701e68312bc07fbc15a3a13814f930718c2c6b0e41a29d035806a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
