{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "---\n",
    "title: \"Implementing Web Search for Large Language Models from Scratch\"\n",
    "author: \"Christian Wittmann\"\n",
    "date: \"2025-03-28\"\n",
    "categories: [llm, ReAct, ai, tools, function_calling]\n",
    "image: \"llm-web-search.png\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Implementing Web Search for Large Language Models from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One major limitation of large language models (LLMs) is that their knowledge is typically constrained by a fixed cutoff date, beyond which they’re unaware of recent events or developments. Fortunately, there’s an effective solution to overcome this limitation: integrating real-time web search capabilities. Although web search functionality is now a standard feature in many LLM web interfaces, it isn’t typically available by default when interacting with an LLM through an API. At first glance, implementing such a feature yourself might seem complicated, but approaching it from first principles simplifies things considerably.\n",
    "\n",
    "In this post, I’ll walk you through how you can quickly and effectively integrate web search functionality into your own LLM projects, from conceptualizing the solution to a practical, step-by-step implementation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "<style>\n",
    "  figure {\n",
    "    display: block;\n",
    "    margin-left: auto;\n",
    "    margin-right: auto;\n",
    "    text-align: center;\n",
    "  }\n",
    "</style>\n",
    "\n",
    "<figure>\n",
    "    <img src=\"llm-web-search.png\" alt=\"LLM Web Search\" style=\"width:50%;\">\n",
    "    <figcaption>LLM Web Search</figcaption>\n",
    "</figure>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conceptual Implementation\n",
    "\n",
    "To break down the challenge, consider two key ideas:\n",
    "\n",
    "- A web search is simply a tool available to the LLM.\n",
    "- A web search operation is essentially just a straightforward API call.\n",
    "\n",
    "Keeping these principles in mind, integrating web search fits neatly into the established “[ReAct](https://arxiv.org/abs/2210.03629)” [1] prompting framework, where an LLM iteratively reasons (thinks) and acts (uses tools) until it achieves its goal. The following diagram illustrates clearly how this integration works in practice:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```{mermaid}\n",
    "sequenceDiagram\n",
    "    autonumber\n",
    "\n",
    "    actor User\n",
    "    participant WebSearch as Web Search\n",
    "    participant Function as Tool\n",
    "    participant ChatClient as Chat Client\n",
    "    participant LLM\n",
    "\n",
    "\n",
    "    User->>Function: Define the web search (API call)\n",
    "    Function->>User: Retrieve JSON function definition\n",
    "    User->>ChatClient: Create Chat Client including web search tool\n",
    "    User->>ChatClient: Send prompt\n",
    "    ChatClient->>LLM: Send prompt with web search tool\n",
    "\n",
    "    loop Reasoning and Acting\n",
    "        LLM->>LLM: Reasoning: Analyze prompt and tools\n",
    "        LLM->>ChatClient: Acting: Generate tool call: web search\n",
    "        ChatClient->>Function: Call web search function\n",
    "        Function->>WebSearch: Call web search API\n",
    "        WebSearch->>Function: Return web search result\n",
    "        Function->>ChatClient: Return web search result\n",
    "        ChatClient->>LLM: Acting: Pass on web search result\n",
    "        LLM->>LLM: Reasoning: Incorporate result and continue reasoning\n",
    "    end\n",
    "\n",
    "    LLM->>ChatClient: Return final result\n",
    "    ChatClient->>User: Output final result\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Now that we have a clear conceptual understanding, let’s walk through the actual implementation step-by-step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Choosing the Right Search Engine\n",
    "\n",
    "When choosing a web search API for this project, simplicity was my top priority. My goal was straightforward: I wanted an API where I could simply input a search query and immediately receive a response that was easy for both me and the LLM to parse.\n",
    "\n",
    "Initially, I considered the obvious choices: popular search engines like [Google](https://developers.google.com/custom-search/v1/introduction) and [Bing](https://learn.microsoft.com/en-us/bing/search-apis/bing-web-search/quickstarts/sdk/web-search-client-library-python). However, I quickly realized that both come with a level of complexity that exceeded my needs.\n",
    "\n",
    "Continuing my search, I came across [Tavily](https://tavily.com), a service I have no affiliation with, but found refreshingly straightforward. Tavily offers an [API](https://docs.tavily.com/documentation/quickstart) tailored specifically for LLM use cases, returning concise, well-structured results. It also provides a generous [free tier of 1,000 requests per month](https://docs.tavily.com/documentation/api-credits), making it ideal for experimentation and quick prototyping.\n",
    "\n",
    "Another potential option I considered was [Brave Search](https://brave.com/search/api/), which also appears to offer an accessible API with minimal overhead. It may be worth exploring if you're looking for alternatives with similar simplicity.\n",
    "\n",
    "Ultimately, I chose Tavily because of its minimal setup, clean responses, and ease of integration—all of which aligned perfectly with the goals of this project."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test Driving the Tavily API\n",
    "\n",
    "Let’s get started by installing the Tavily Python library: _(As usual, there’s a [Jupyter notebook version](https://github.com/chrwittm/chrwittm.github.io/blob/main/posts/2025-03-28-llm-web-search/index.ipynb) of this blog post if you want to run the code yourself.)_\n",
    "\n",
    "```sh\n",
    "!pip install tavily-python\n",
    "```\n",
    "\n",
    "Before integrating Tavily with our LLM, it’s a good practice to test the service independently. While the free tier provides plenty of room for testing, I chose to initially use a cached mock response to minimize unnecessary API calls. This approach ensures our logic and parsing methods work correctly before we start consuming real API credits.\n",
    "\n",
    "Here is an example of a mock response from Tavily for the query _“Who is Leo Messi?”_:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "mock_response = \"\"\"{\n",
    "    \"answer\": null,\n",
    "    \"follow_up_questions\": null,\n",
    "    \"images\": [],\n",
    "    \"query\": \"Who is Leo Messi?\",\n",
    "    \"response_time\": 1.75,\n",
    "    \"results\": [\n",
    "        {\n",
    "            \"content\": \"Lionel Messi is an Argentine-born football (soccer) player who has been named the world’s best men’s player of the year seven times (2009–12, 2015, 2019, and 2021). In 2022 he helped Argentina win the World Cup. Naturally left-footed, quick, and precise in control of the ball, Messi is known as a keen pass distributor and can readily thread his way through packed defenses. He led Argentina’s national team to win the 2021 Copa América and the 2022 World Cup, when he again won the Golden Ball award.\",\n",
    "            \"raw_content\": null,\n",
    "            \"score\": 0.84027237,\n",
    "            \"title\": \"Lionel Messi | Biography, Trophies, Records, Ballon d'Or, Inter Miami ...\",\n",
    "            \"url\": \"https://www.britannica.com/biography/Lionel-Messi\"\n",
    "        },\n",
    "        {\n",
    "            \"content\": \"Widely regarded as one of the greatest players of all time, Messi set numerous records for individual accolades won throughout his professional footballing career such as eight Ballon d'Or awards and four the Best FIFA Men's Player awards. A prolific goalscorer and creative playmaker, Messi has scored over 850 senior career goals and has provided over 380 assists for club and country. [16] Born in Rosario, Argentina, Messi relocated to Spain to join Barcelona at age 13, and made his competitive debut at age 17 in October 2004. An Argentine international, Messi is the national team's all-time leading goalscorer and most-capped player. His style of play as a diminutive, left-footed dribbler drew career-long comparisons with compatriot Diego Maradona, who described Messi as his successor.\",\n",
    "            \"raw_content\": null,\n",
    "            \"score\": 0.8091708,\n",
    "            \"title\": \"Lionel Messi - Wikipedia\",\n",
    "            \"url\": \"https://en.wikipedia.org/wiki/Lionel_Messi\"\n",
    "        }\n",
    "    ]\n",
    "}\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "from IPython.display import display, Code\n",
    "\n",
    "def display_json(data):\n",
    "    \"\"\"\n",
    "    Nicely displays JSON content: indented + syntax-highlighted.\n",
    "    \n",
    "    Args:\n",
    "        data (str | dict | list): The JSON or string to display.\n",
    "    \"\"\"\n",
    "    # Parse if input is a string\n",
    "    if isinstance(data, str):\n",
    "        try:\n",
    "            data = ast.literal_eval(data)\n",
    "        except Exception as e:\n",
    "            print(\"Failed to parse string input as JSON-like structure.\")\n",
    "            print(\"Error:\", e)\n",
    "            return\n",
    "\n",
    "    # Convert to pretty JSON string\n",
    "    pretty_json = json.dumps(data, indent=4, sort_keys=True, ensure_ascii=False)\n",
    "\n",
    "    # Display with syntax highlighting\n",
    "    display(Code(pretty_json, language='json'))\n",
    "\n",
    "import json\n",
    "import ast\n",
    "\n",
    "def parse_mock_response(response_str: str):\n",
    "    try:\n",
    "        return json.loads(response_str)\n",
    "    except json.JSONDecodeError:\n",
    "        try:\n",
    "            return ast.literal_eval(response_str)\n",
    "        except Exception as e:\n",
    "            print(\"❌ Failed to parse mock response:\", e)\n",
    "            return {}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's run our first query."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "use_api = False\n",
    "\n",
    "load_dotenv()\n",
    "api_key = os.getenv(\"TAVILY_API_KEY\")\n",
    "if not api_key:\n",
    "    raise ValueError(\"TAVILY_API_KEY not found in .env file.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>pre { line-height: 125%; }\n",
       "td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }\n",
       "td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       "span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }\n",
       ".output_html .hll { background-color: #ffffcc }\n",
       ".output_html { background: #f8f8f8; }\n",
       ".output_html .c { color: #3D7B7B; font-style: italic } /* Comment */\n",
       ".output_html .err { border: 1px solid #FF0000 } /* Error */\n",
       ".output_html .k { color: #008000; font-weight: bold } /* Keyword */\n",
       ".output_html .o { color: #666666 } /* Operator */\n",
       ".output_html .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */\n",
       ".output_html .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */\n",
       ".output_html .cp { color: #9C6500 } /* Comment.Preproc */\n",
       ".output_html .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */\n",
       ".output_html .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */\n",
       ".output_html .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */\n",
       ".output_html .gd { color: #A00000 } /* Generic.Deleted */\n",
       ".output_html .ge { font-style: italic } /* Generic.Emph */\n",
       ".output_html .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */\n",
       ".output_html .gr { color: #E40000 } /* Generic.Error */\n",
       ".output_html .gh { color: #000080; font-weight: bold } /* Generic.Heading */\n",
       ".output_html .gi { color: #008400 } /* Generic.Inserted */\n",
       ".output_html .go { color: #717171 } /* Generic.Output */\n",
       ".output_html .gp { color: #000080; font-weight: bold } /* Generic.Prompt */\n",
       ".output_html .gs { font-weight: bold } /* Generic.Strong */\n",
       ".output_html .gu { color: #800080; font-weight: bold } /* Generic.Subheading */\n",
       ".output_html .gt { color: #0044DD } /* Generic.Traceback */\n",
       ".output_html .kc { color: #008000; font-weight: bold } /* Keyword.Constant */\n",
       ".output_html .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */\n",
       ".output_html .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */\n",
       ".output_html .kp { color: #008000 } /* Keyword.Pseudo */\n",
       ".output_html .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */\n",
       ".output_html .kt { color: #B00040 } /* Keyword.Type */\n",
       ".output_html .m { color: #666666 } /* Literal.Number */\n",
       ".output_html .s { color: #BA2121 } /* Literal.String */\n",
       ".output_html .na { color: #687822 } /* Name.Attribute */\n",
       ".output_html .nb { color: #008000 } /* Name.Builtin */\n",
       ".output_html .nc { color: #0000FF; font-weight: bold } /* Name.Class */\n",
       ".output_html .no { color: #880000 } /* Name.Constant */\n",
       ".output_html .nd { color: #AA22FF } /* Name.Decorator */\n",
       ".output_html .ni { color: #717171; font-weight: bold } /* Name.Entity */\n",
       ".output_html .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */\n",
       ".output_html .nf { color: #0000FF } /* Name.Function */\n",
       ".output_html .nl { color: #767600 } /* Name.Label */\n",
       ".output_html .nn { color: #0000FF; font-weight: bold } /* Name.Namespace */\n",
       ".output_html .nt { color: #008000; font-weight: bold } /* Name.Tag */\n",
       ".output_html .nv { color: #19177C } /* Name.Variable */\n",
       ".output_html .ow { color: #AA22FF; font-weight: bold } /* Operator.Word */\n",
       ".output_html .w { color: #bbbbbb } /* Text.Whitespace */\n",
       ".output_html .mb { color: #666666 } /* Literal.Number.Bin */\n",
       ".output_html .mf { color: #666666 } /* Literal.Number.Float */\n",
       ".output_html .mh { color: #666666 } /* Literal.Number.Hex */\n",
       ".output_html .mi { color: #666666 } /* Literal.Number.Integer */\n",
       ".output_html .mo { color: #666666 } /* Literal.Number.Oct */\n",
       ".output_html .sa { color: #BA2121 } /* Literal.String.Affix */\n",
       ".output_html .sb { color: #BA2121 } /* Literal.String.Backtick */\n",
       ".output_html .sc { color: #BA2121 } /* Literal.String.Char */\n",
       ".output_html .dl { color: #BA2121 } /* Literal.String.Delimiter */\n",
       ".output_html .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */\n",
       ".output_html .s2 { color: #BA2121 } /* Literal.String.Double */\n",
       ".output_html .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */\n",
       ".output_html .sh { color: #BA2121 } /* Literal.String.Heredoc */\n",
       ".output_html .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */\n",
       ".output_html .sx { color: #008000 } /* Literal.String.Other */\n",
       ".output_html .sr { color: #A45A77 } /* Literal.String.Regex */\n",
       ".output_html .s1 { color: #BA2121 } /* Literal.String.Single */\n",
       ".output_html .ss { color: #19177C } /* Literal.String.Symbol */\n",
       ".output_html .bp { color: #008000 } /* Name.Builtin.Pseudo */\n",
       ".output_html .fm { color: #0000FF } /* Name.Function.Magic */\n",
       ".output_html .vc { color: #19177C } /* Name.Variable.Class */\n",
       ".output_html .vg { color: #19177C } /* Name.Variable.Global */\n",
       ".output_html .vi { color: #19177C } /* Name.Variable.Instance */\n",
       ".output_html .vm { color: #19177C } /* Name.Variable.Magic */\n",
       ".output_html .il { color: #666666 } /* Literal.Number.Integer.Long */</style><div class=\"highlight\"><pre><span></span><span class=\"p\">{</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">&quot;answer&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">null</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">&quot;follow_up_questions&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">null</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">&quot;images&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[],</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">&quot;query&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">&quot;Who is Leo Messi?&quot;</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">&quot;response_time&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mf\">1.75</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">    </span><span class=\"nt\">&quot;results&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"p\">[</span>\n",
       "<span class=\"w\">        </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">            </span><span class=\"nt\">&quot;content&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">&quot;Lionel Messi is an Argentine-born football (soccer) player who has been named the world’s best men’s player of the year seven times (2009–12, 2015, 2019, and 2021). In 2022 he helped Argentina win the World Cup. Naturally left-footed, quick, and precise in control of the ball, Messi is known as a keen pass distributor and can readily thread his way through packed defenses. He led Argentina’s national team to win the 2021 Copa América and the 2022 World Cup, when he again won the Golden Ball award.&quot;</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">            </span><span class=\"nt\">&quot;raw_content&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">null</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">            </span><span class=\"nt\">&quot;score&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mf\">0.84027237</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">            </span><span class=\"nt\">&quot;title&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">&quot;Lionel Messi | Biography, Trophies, Records, Ballon d&#39;Or, Inter Miami ...&quot;</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">            </span><span class=\"nt\">&quot;url&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">&quot;https://www.britannica.com/biography/Lionel-Messi&quot;</span>\n",
       "<span class=\"w\">        </span><span class=\"p\">},</span>\n",
       "<span class=\"w\">        </span><span class=\"p\">{</span>\n",
       "<span class=\"w\">            </span><span class=\"nt\">&quot;content&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">&quot;Widely regarded as one of the greatest players of all time, Messi set numerous records for individual accolades won throughout his professional footballing career such as eight Ballon d&#39;Or awards and four the Best FIFA Men&#39;s Player awards. A prolific goalscorer and creative playmaker, Messi has scored over 850 senior career goals and has provided over 380 assists for club and country. [16] Born in Rosario, Argentina, Messi relocated to Spain to join Barcelona at age 13, and made his competitive debut at age 17 in October 2004. An Argentine international, Messi is the national team&#39;s all-time leading goalscorer and most-capped player. His style of play as a diminutive, left-footed dribbler drew career-long comparisons with compatriot Diego Maradona, who described Messi as his successor.&quot;</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">            </span><span class=\"nt\">&quot;raw_content&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"kc\">null</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">            </span><span class=\"nt\">&quot;score&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"mf\">0.8091708</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">            </span><span class=\"nt\">&quot;title&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">&quot;Lionel Messi - Wikipedia&quot;</span><span class=\"p\">,</span>\n",
       "<span class=\"w\">            </span><span class=\"nt\">&quot;url&quot;</span><span class=\"p\">:</span><span class=\"w\"> </span><span class=\"s2\">&quot;https://en.wikipedia.org/wiki/Lionel_Messi&quot;</span>\n",
       "<span class=\"w\">        </span><span class=\"p\">}</span>\n",
       "<span class=\"w\">    </span><span class=\"p\">]</span>\n",
       "<span class=\"p\">}</span>\n",
       "</pre></div>\n"
      ],
      "text/latex": [
       "\\begin{Verbatim}[commandchars=\\\\\\{\\}]\n",
       "\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{    }\\PY{n+nt}{\\PYZdq{}answer\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{k+kc}{null}\\PY{p}{,}\n",
       "\\PY{+w}{    }\\PY{n+nt}{\\PYZdq{}follow\\PYZus{}up\\PYZus{}questions\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{k+kc}{null}\\PY{p}{,}\n",
       "\\PY{+w}{    }\\PY{n+nt}{\\PYZdq{}images\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{p}{[],}\n",
       "\\PY{+w}{    }\\PY{n+nt}{\\PYZdq{}query\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s+s2}{\\PYZdq{}Who is Leo Messi?\\PYZdq{}}\\PY{p}{,}\n",
       "\\PY{+w}{    }\\PY{n+nt}{\\PYZdq{}response\\PYZus{}time\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{l+m+mf}{1.75}\\PY{p}{,}\n",
       "\\PY{+w}{    }\\PY{n+nt}{\\PYZdq{}results\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{p}{[}\n",
       "\\PY{+w}{        }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{            }\\PY{n+nt}{\\PYZdq{}content\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s+s2}{\\PYZdq{}Lionel Messi is an Argentine\\PYZhy{}born football (soccer) player who has been named the world’s best men’s player of the year seven times (2009–12, 2015, 2019, and 2021). In 2022 he helped Argentina win the World Cup. Naturally left\\PYZhy{}footed, quick, and precise in control of the ball, Messi is known as a keen pass distributor and can readily thread his way through packed defenses. He led Argentina’s national team to win the 2021 Copa América and the 2022 World Cup, when he again won the Golden Ball award.\\PYZdq{}}\\PY{p}{,}\n",
       "\\PY{+w}{            }\\PY{n+nt}{\\PYZdq{}raw\\PYZus{}content\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{k+kc}{null}\\PY{p}{,}\n",
       "\\PY{+w}{            }\\PY{n+nt}{\\PYZdq{}score\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{l+m+mf}{0.84027237}\\PY{p}{,}\n",
       "\\PY{+w}{            }\\PY{n+nt}{\\PYZdq{}title\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s+s2}{\\PYZdq{}Lionel Messi | Biography, Trophies, Records, Ballon d\\PYZsq{}Or, Inter Miami ...\\PYZdq{}}\\PY{p}{,}\n",
       "\\PY{+w}{            }\\PY{n+nt}{\\PYZdq{}url\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s+s2}{\\PYZdq{}https://www.britannica.com/biography/Lionel\\PYZhy{}Messi\\PYZdq{}}\n",
       "\\PY{+w}{        }\\PY{p}{\\PYZcb{},}\n",
       "\\PY{+w}{        }\\PY{p}{\\PYZob{}}\n",
       "\\PY{+w}{            }\\PY{n+nt}{\\PYZdq{}content\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s+s2}{\\PYZdq{}Widely regarded as one of the greatest players of all time, Messi set numerous records for individual accolades won throughout his professional footballing career such as eight Ballon d\\PYZsq{}Or awards and four the Best FIFA Men\\PYZsq{}s Player awards. A prolific goalscorer and creative playmaker, Messi has scored over 850 senior career goals and has provided over 380 assists for club and country. [16] Born in Rosario, Argentina, Messi relocated to Spain to join Barcelona at age 13, and made his competitive debut at age 17 in October 2004. An Argentine international, Messi is the national team\\PYZsq{}s all\\PYZhy{}time leading goalscorer and most\\PYZhy{}capped player. His style of play as a diminutive, left\\PYZhy{}footed dribbler drew career\\PYZhy{}long comparisons with compatriot Diego Maradona, who described Messi as his successor.\\PYZdq{}}\\PY{p}{,}\n",
       "\\PY{+w}{            }\\PY{n+nt}{\\PYZdq{}raw\\PYZus{}content\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{k+kc}{null}\\PY{p}{,}\n",
       "\\PY{+w}{            }\\PY{n+nt}{\\PYZdq{}score\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{l+m+mf}{0.8091708}\\PY{p}{,}\n",
       "\\PY{+w}{            }\\PY{n+nt}{\\PYZdq{}title\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s+s2}{\\PYZdq{}Lionel Messi \\PYZhy{} Wikipedia\\PYZdq{}}\\PY{p}{,}\n",
       "\\PY{+w}{            }\\PY{n+nt}{\\PYZdq{}url\\PYZdq{}}\\PY{p}{:}\\PY{+w}{ }\\PY{l+s+s2}{\\PYZdq{}https://en.wikipedia.org/wiki/Lionel\\PYZus{}Messi\\PYZdq{}}\n",
       "\\PY{+w}{        }\\PY{p}{\\PYZcb{}}\n",
       "\\PY{+w}{    }\\PY{p}{]}\n",
       "\\PY{p}{\\PYZcb{}}\n",
       "\\end{Verbatim}\n"
      ],
      "text/plain": [
       "{\n",
       "    \"answer\": null,\n",
       "    \"follow_up_questions\": null,\n",
       "    \"images\": [],\n",
       "    \"query\": \"Who is Leo Messi?\",\n",
       "    \"response_time\": 1.75,\n",
       "    \"results\": [\n",
       "        {\n",
       "            \"content\": \"Lionel Messi is an Argentine-born football (soccer) player who has been named the world’s best men’s player of the year seven times (2009–12, 2015, 2019, and 2021). In 2022 he helped Argentina win the World Cup. Naturally left-footed, quick, and precise in control of the ball, Messi is known as a keen pass distributor and can readily thread his way through packed defenses. He led Argentina’s national team to win the 2021 Copa América and the 2022 World Cup, when he again won the Golden Ball award.\",\n",
       "            \"raw_content\": null,\n",
       "            \"score\": 0.84027237,\n",
       "            \"title\": \"Lionel Messi | Biography, Trophies, Records, Ballon d'Or, Inter Miami ...\",\n",
       "            \"url\": \"https://www.britannica.com/biography/Lionel-Messi\"\n",
       "        },\n",
       "        {\n",
       "            \"content\": \"Widely regarded as one of the greatest players of all time, Messi set numerous records for individual accolades won throughout his professional footballing career such as eight Ballon d'Or awards and four the Best FIFA Men's Player awards. A prolific goalscorer and creative playmaker, Messi has scored over 850 senior career goals and has provided over 380 assists for club and country. [16] Born in Rosario, Argentina, Messi relocated to Spain to join Barcelona at age 13, and made his competitive debut at age 17 in October 2004. An Argentine international, Messi is the national team's all-time leading goalscorer and most-capped player. His style of play as a diminutive, left-footed dribbler drew career-long comparisons with compatriot Diego Maradona, who described Messi as his successor.\",\n",
       "            \"raw_content\": null,\n",
       "            \"score\": 0.8091708,\n",
       "            \"title\": \"Lionel Messi - Wikipedia\",\n",
       "            \"url\": \"https://en.wikipedia.org/wiki/Lionel_Messi\"\n",
       "        }\n",
       "    ]\n",
       "}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "from tavily import TavilyClient\n",
    "\n",
    "query = \"Who is Leo Messi?\"\n",
    "\n",
    "if use_api:\n",
    "    tavily_client = TavilyClient(api_key=api_key)\n",
    "    response = tavily_client.search(\n",
    "        query=query,\n",
    "        search_depth=\"basic\",\n",
    "        include_answer=False,\n",
    "        include_raw_content=False,\n",
    "        max_results=2\n",
    "    )\n",
    "else:\n",
    "    response = parse_mock_response(mock_response)\n",
    "\n",
    "display_json(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Formatting Search Results for the LLM\n",
    "\n",
    "Although large language models are capable of parsing raw JSON, this format isn't ideal. It introduces unnecessary token overhead and lacks the readability and structure that both humans and LLMs benefit from. To make the results easier to consume, we'll reformat the API response into clean, human-readable Markdown. This improves clarity, ensures more predictable behavior from the LLM, and also makes the output easier to debug and inspect during development."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "def format_tavily_results(response: dict, max_results: int = 5, snippet_length: int = 5000) -> str:\n",
    "    \"\"\"\n",
    "    Formats the Tavily search API JSON response into a readable, LLM-friendly string.\n",
    "\n",
    "    Args:\n",
    "        response (dict): The Tavily API response.\n",
    "        max_results (int): Maximum number of results to include.\n",
    "        snippet_length (int): Max number of characters to show from each result's content.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted, readable string for LLM consumption.\n",
    "    \"\"\"\n",
    "    results = response.get(\"results\", [])\n",
    "    if not results:\n",
    "        return \"No results found.\"\n",
    "\n",
    "    formatted = \"### Web Search Results:\\n\\n\"\n",
    "    for i, result in enumerate(results[:max_results], start=1):\n",
    "        title = result.get(\"title\", \"Untitled\")\n",
    "        url = result.get(\"url\", \"\")\n",
    "        content = result.get(\"content\", \"\") or \"\"\n",
    "        snippet = content.strip().replace(\"\\n\", \" \")[:snippet_length].rstrip()\n",
    "        \n",
    "        # Clean up unfinished sentences if needed\n",
    "        if snippet and not snippet.endswith(('.', '!', '?')):\n",
    "            snippet += \"...\"\n",
    "\n",
    "        formatted += f\"{i}. **[{title}]({url})**\\n   - {snippet}\\n\\n\"\n",
    "\n",
    "    return formatted.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Web Search Results:\n",
      "\n",
      "1. **[Lionel Messi | Biography, Trophies, Records, Ballon d'Or, Inter Miami ...](https://www.britannica.com/biography/Lionel-Messi)**\n",
      "   - Lionel Messi is an Argentine-born football (soccer) player who has been named the world’s best men’s player of the year seven times (2009–12, 2015, 2019, and 2021). In 2022 he helped Argentina win the World Cup. Naturally left-footed, quick, and precise in control of the ball, Messi is known as a ke...\n",
      "\n",
      "2. **[Lionel Messi - Wikipedia](https://en.wikipedia.org/wiki/Lionel_Messi)**\n",
      "   - Widely regarded as one of the greatest players of all time, Messi set numerous records for individual accolades won throughout his professional footballing career such as eight Ballon d'Or awards and four the Best FIFA Men's Player awards. A prolific goalscorer and creative playmaker, Messi has scor...\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "formatted = format_tavily_results(response, snippet_length=300)\n",
    "print(formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM can now easily consume the text summaries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Defining Web Search Tool for the LLM\n",
    "\n",
    "Next, we’ll encapsulate our functionality into a single, reusable function that performs both API calls and formatting. Additionally, we need to define a proper documentation so that the LLM can understand how to use our tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "def search_web(query: str) -> str:\n",
    "    \"\"\"\n",
    "    Searches the web using Tavily and returns a formatted result.\n",
    "\n",
    "    Args:\n",
    "        query (str): The search query string.\n",
    "\n",
    "    Returns:\n",
    "        str: Formatted search results for LLM input.\n",
    "    \"\"\"\n",
    "    if use_api:\n",
    "        tavily_client = TavilyClient(api_key=api_key)\n",
    "        response = tavily_client.search(\n",
    "            query=query,\n",
    "            search_depth=\"basic\",\n",
    "            include_answer=False,\n",
    "            include_raw_content=False,\n",
    "            max_results=5\n",
    "        )\n",
    "    else:\n",
    "        response = parse_mock_response(mock_response)\n",
    "\n",
    "    return format_tavily_results(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is an example-call including the result the LLM would receive:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### Web Search Results:\n",
      "\n",
      "1. **[Lionel Messi | Biography, Trophies, Records, Ballon d'Or, Inter Miami ...](https://www.britannica.com/biography/Lionel-Messi)**\n",
      "   - Lionel Messi is an Argentine-born football (soccer) player who has been named the world’s best men’s player of the year seven times (2009–12, 2015, 2019, and 2021). In 2022 he helped Argentina win the World Cup. Naturally left-footed, quick, and precise in control of the ball, Messi is known as a keen pass distributor and can readily thread his way through packed defenses. He led Argentina’s national team to win the 2021 Copa América and the 2022 World Cup, when he again won the Golden Ball award.\n",
      "\n",
      "2. **[Lionel Messi - Wikipedia](https://en.wikipedia.org/wiki/Lionel_Messi)**\n",
      "   - Widely regarded as one of the greatest players of all time, Messi set numerous records for individual accolades won throughout his professional footballing career such as eight Ballon d'Or awards and four the Best FIFA Men's Player awards. A prolific goalscorer and creative playmaker, Messi has scored over 850 senior career goals and has provided over 380 assists for club and country. [16] Born in Rosario, Argentina, Messi relocated to Spain to join Barcelona at age 13, and made his competitive debut at age 17 in October 2004. An Argentine international, Messi is the national team's all-time leading goalscorer and most-capped player. His style of play as a diminutive, left-footed dribbler drew career-long comparisons with compatriot Diego Maradona, who described Messi as his successor.\n"
     ]
    }
   ],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "result = search_web(\"Who is Leo Messi?\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 5: Exposing the Web Search Tool to the LLM\n",
    "\n",
    "To expose our web search to an LLM, we need to provide the tool definition to the LLM. Jeremy Howard shared a practical and flexible approach for this in his [Hacker's Guide](https://github.com/fastai/lm-hackers/blob/main/lm-hackers.ipynb). The core idea is to use Python's introspection capabilities to extract the function signature and documentation, and convert it into a schema the LLM can understand. The version used here builds on that idea, with minor updates to match recent changes in the OpenAI tools API.\n",
    "\n",
    "The most important part of this process is clearly documenting the function’s interface: Its name, parameters, and behavior—so that the LLM knows how and when to call it. This allows the model to use the tool automatically, without any additional prompting logic or manual wiring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import create_model\n",
    "import inspect, json\n",
    "from inspect import Parameter\n",
    "\n",
    "def get_schema(f):\n",
    "    kw = {n:(o.annotation, ... if o.default==Parameter.empty else o.default)\n",
    "          for n,o in inspect.signature(f).parameters.items()}\n",
    "    # update: schema -> model_json_schema\n",
    "    s = create_model(f'Input for `{f.__name__}`', **kw).model_json_schema()\n",
    "    # update: added function level in tools json\n",
    "    function_params = dict(name=f.__name__, description=f.__doc__, parameters=s)\n",
    "    return dict(type=\"function\", function=function_params)\n",
    "\n",
    "funcs_ok = {'search_web'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'search_web',\n",
       "   'description': '\\n    Searches the web using Tavily and returns a formatted result.\\n\\n    Args:\\n        query (str): The search query string.\\n\\n    Returns:\\n        str: Formatted search results for LLM input.\\n    ',\n",
       "   'parameters': {'properties': {'query': {'title': 'Query',\n",
       "      'type': 'string'}},\n",
       "    'required': ['query'],\n",
       "    'title': 'Input for `search_web`',\n",
       "    'type': 'object'}}}]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_tools():\n",
    "    return [get_schema(search_web)]\n",
    "\n",
    "get_tools()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, any compatible LLM can automatically invoke `search_web` when needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 6: Reuse Chat Client for LLM communication\n",
    "\n",
    "Let's use a simple custom client (which you can learn more about in [this blog post](https://chrwittm.github.io/posts/2024-08-02-llm-calculator2-vision/)) to try out our search tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "class ChatMessages:\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"Initializes the Chat.\"\"\"\n",
    "        self._messages = []\n",
    "\n",
    "    def _append_message(self, role, content):\n",
    "        \"\"\"Appends a message with specified role and content to messages list.\"\"\"\n",
    "        self._messages.append({\"role\": role, \"content\": content})\n",
    "\n",
    "    def append_system_message(self, content):\n",
    "        \"\"\"Appends a system message with specified content to messages list.\"\"\"\n",
    "        self._append_message(\"system\", content)\n",
    "    \n",
    "    def append_tool_message(self, content, tool_call_id):\n",
    "        \"\"\"Appends a tool message with specified content to messages list.\"\"\"\n",
    "        self._messages.append({\"role\": \"tool\", \"content\": content, \"tool_call_id\": tool_call_id})\n",
    "\n",
    "    def append_user_message(self, content=None, base64_image=None):\n",
    "        \"\"\"Appends a user message with specified content to messages list.\"\"\"\n",
    "        if base64_image:\n",
    "            image_content = [\n",
    "                {\"type\": \"text\", \"text\": content},\n",
    "                {\"type\": \"image_url\", \"image_url\": {\"url\": f\"data:image/png;base64,{base64_image}\"}}\n",
    "            ]\n",
    "            self._messages.append({\"role\": \"user\", \"content\": image_content})  \n",
    "        else:\n",
    "            self._append_message(\"user\", content)\n",
    "\n",
    "#    def append_assistant_message(self, content=None, tool_calls=None):\n",
    "#        \"\"\"Appends an assistant message with specified content to messages list.\"\"\"\n",
    "#        if content:\n",
    "#            self._append_message(\"assistant\", content)\n",
    "#        else:\n",
    "#            self._messages.append({\"role\": \"assistant\", \"tool_calls\": tool_calls})\n",
    "\n",
    "    def append_assistant_message(self, content=None, tool_calls=None):\n",
    "        \"\"\"Appends an assistant message with optional content and tool calls.\"\"\"\n",
    "        message = {\"role\": \"assistant\"}\n",
    "        \n",
    "        if content is not None:\n",
    "            message[\"content\"] = content\n",
    "        \n",
    "        if tool_calls is not None:\n",
    "            message[\"tool_calls\"] = tool_calls\n",
    "\n",
    "        self._messages.append(message)\n",
    "\n",
    "    def get_messages(self):\n",
    "        \"\"\"Returns a shallow copy of the messages list.\"\"\"\n",
    "        return self._messages[:]\n",
    "    \n",
    "    def get_last_assistant_message(self):\n",
    "        \"\"\"Returns the content of the last assistant message\"\"\"\n",
    "        return self._messages[-1]['content']\n",
    "    \n",
    "    def get_debug_view(self):\n",
    "        \"\"\"Returns the debug view of the chat messages formatted as Markdown.\"\"\"\n",
    "        debug_view = []\n",
    "        for message in self._messages:\n",
    "            role = message.get('role')\n",
    "            content = message.get('content', '')\n",
    "\n",
    "            if role == 'system' or role == 'user':\n",
    "                debug_view.append(f\"**{role}**: {content}\\n\")\n",
    "\n",
    "            elif role == 'assistant':\n",
    "                if 'tool_calls' in message:\n",
    "                    debug_view.append(\"**tool calls**\\n\")\n",
    "                    for i, tool_call in enumerate(message['tool_calls'], start=1):\n",
    "                        function_name = tool_call.function.name\n",
    "                        arguments = tool_call.function.arguments\n",
    "                        tool_call_id = tool_call.id\n",
    "                        debug_view.append(f\"{i}. tool: {function_name}: {arguments} (tool call id: {tool_call_id})\\n\")\n",
    "                else:\n",
    "                    debug_view.append(f\"**assistant**: {content}\\n\")\n",
    "\n",
    "            elif role == 'tool':\n",
    "                tool_call_id = message.get('tool_call_id', '')\n",
    "                debug_view.append(f\"**tool result**: {content} (tool call id: {tool_call_id})\\n\")\n",
    "\n",
    "        return Markdown('\\n'.join(debug_view))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| code-fold: true\n",
    "\n",
    "model_name = \"gpt-4o\"\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv(\".env\")\n",
    "\n",
    "from openai import chat\n",
    "\n",
    "class ChatClient:\n",
    "\n",
    "    def __init__(self, system_message=None, tools=None):\n",
    "        \"\"\"Initializes the Chat with the system message.\"\"\"\n",
    "        self._chat_messages = ChatMessages()\n",
    "        if system_message:\n",
    "            self._chat_messages.append_system_message(system_message)\n",
    "        self._tools = tools\n",
    "\n",
    "    def call_tool(self, tool_call):\n",
    "        \"\"\"returns the result of an LLM tool call\"\"\"\n",
    "        fc = tool_call.function #Updated\n",
    "        if fc.name not in funcs_ok: return print(f'Not allowed: {fc.name}')\n",
    "        f = globals()[fc.name]\n",
    "        return f(**json.loads(fc.arguments))\n",
    "\n",
    "    def call_tools(self, tool_calls):\n",
    "        \"\"\"Processes the tool calls of the LLM response and calls the LLM API again\"\"\"\n",
    "        for tool_call in tool_calls:\n",
    "            chat_client._chat_messages.append_tool_message(\n",
    "                content=str(self.call_tool(tool_call)),\n",
    "                tool_call_id=tool_call.id)\n",
    "            \n",
    "        self.ask_gpt()\n",
    "\n",
    "    def get_model_response(self):\n",
    "        \"\"\"Calls the LLM chat completion API\"\"\"\n",
    "        return chat.completions.create(\n",
    "            model=model_name,\n",
    "            messages=self._chat_messages.get_messages(),\n",
    "            tools=self._tools)\n",
    "\n",
    "    def ask_gpt(self, prompt=None, base64_image=None):\n",
    "        \n",
    "        if base64_image:\n",
    "            self._chat_messages.append_user_message(content=prompt, base64_image=base64_image)\n",
    "\n",
    "        if prompt:\n",
    "            self._chat_messages.append_user_message(prompt)\n",
    "\n",
    "        c = self.get_model_response()\n",
    "        content = c.choices[0].message.content\n",
    "        tool_calls = c.choices[0].message.tool_calls\n",
    "\n",
    "        self._chat_messages.append_assistant_message(\n",
    "            content=content,\n",
    "            tool_calls=tool_calls)\n",
    "        \n",
    "        if tool_calls:\n",
    "            self.call_tools(tool_calls)\n",
    "\n",
    "        return Markdown(self._chat_messages.get_last_assistant_message())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's quickly confirm that we can talk to the large language model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Mercury, Venus, Earth, Mars, Jupiter, Saturn, Uranus, Neptune."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "chat_client = ChatClient(\"Answer in a very concise and accurate way\")\n",
    "chat_client.ask_gpt(\"Name the planets in the solar system\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 7: Chat with Mock Web Search\n",
    "\n",
    "Now that we have established communication with the LLM, let's try out our mock search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I searched for \"bioluminescent algae\" but received results about Lionel Messi, a famed Argentine-born football player. Messi is widely regarded as one of the greatest footballers of all time, having won numerous accolades including multiple Ballon d'Or and FIFA Men's Player awards. Despite his achievements in football, my search did not yield any information relevant to bioluminescent algae. This kind of unexpected result can sometimes happen during searches. If you'd like to try another topic, feel free to ask!"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "system_prompt = \"\"\"You are a helpful assistant. \\\n",
    "                   When you search the web, make sure to cite your sources.\"\"\"\n",
    "chat_client = ChatClient(system_message=system_prompt, tools=get_tools())\n",
    "chat_client.ask_gpt(\"Search the web on a random topic and tell me what you find. \\\n",
    "                     - do not be surprised if the result does not match the query\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Without real-time search (`use_api = False`), the model always receives the search results about Messi."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 8: Chat with real Web Search\n",
    "\n",
    "Let’s put everything to the test with a different search query: _\"Who won the German elections in 2025?\"_\n",
    "\n",
    "Before enabling the real-time web search, we’ll first run this prompt with no tools attached. This allows us to confirm the baseline: The LLM cannot answer the question, because of its earlier cut-off date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "I'm unable to provide information on events beyond October 2023, as my training data only goes up until that point. You may want to check the latest news or the official German election website for up-to-date information on the 2025 German elections."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "chat_client = ChatClient(system_message=system_prompt)\n",
    "chat_client.ask_gpt(\"Who won the German elections in 2025?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we activate tool use, we get an answer which is grounded in our Internet search."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The German federal election in 2025 was won by the Christian Democratic Union (CDU), led by Friedrich Merz. The CDU secured 28.5% of the popular vote and won 208 seats in the Bundestag, making them the majority party in the election [source](https://en.wikipedia.org/wiki/2025_German_federal_election)."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#| code-fold: false\n",
    "\n",
    "use_api = True\n",
    "chat_client = ChatClient(system_message=system_prompt, tools=get_tools())\n",
    "chat_client.ask_gpt(\"Who won the German elections in 2025?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LLM now successfully retrieves and incorporates current information directly from the web."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "When we set out to implement real-time web search for large language models, we defined two key principles:\n",
    "\n",
    "- Web search is just a tool for the LLM.\n",
    "- Web search is just a straightforward API call.\n",
    "\n",
    "By sticking closely to these ideas, we’ve successfully implemented a real-time web search functionality for large language models in just a few lines of code. We created a practical and lightweight integration that significantly improves the usefulness of LLMs when accessed via APIs.\n",
    "\n",
    "This approach shows that enhancing your model’s capabilities doesn’t require complicated setups or extensive boilerplate. With minimal effort, you can empower your models to get access to up-to-date, accurate information, making them even more valuable in everyday use.\n",
    "\n",
    "Feel free to use this simple integration pattern as a starting point to extend your own LLM-based projects further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "[1] Yao, S., Yu, T., Wu, Y., Zhao, Z., Yu, K., & Liu, S. (2022). [ReAct: Synergizing Reasoning and Acting in Language Models](https://arxiv.org/abs/2210.03629)\n",
    "\n",
    "[2] Howard, J. (2023). [A Hackers' Guide to Language Models](https://youtu.be/jkrNMKz9pWU?si=88WgZx2u3HaldCgj)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
