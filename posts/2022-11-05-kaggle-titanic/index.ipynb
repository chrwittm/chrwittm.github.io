{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"My First Kaggle Competition: Titanic\"\n",
    "author: \"Christian Wittmann\"\n",
    "date: \"2022-11-05\"\n",
    "categories: [kaggle, titanic, fast.ai, ml, tabular]\n",
    "image: \"Kaggle_logo.png\"\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more practical experience with gradient descent, I decided to participate in the [Titanic Competition](https://www.kaggle.com/c/titanic). Here is how I did it and what I learned.\n",
    "\n",
    "I took the following approach:\n",
    "\n",
    "* Setting up my local machine for the Kaggle competition\n",
    "* Trying to write as little code as possible, I implemented [notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/titanic/titanic1/titanic1.ipynb) which leveraged a fast.ai tabular learner\n",
    "* Creating another [notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/titanic/titanic3/titanic3.ipynb) re-implementing Jeremy's Excel-based model\n",
    "\n",
    "> Note: This blog post itself is a notebook, and it can be found [here on GitHub](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/titanic/titanic-blog-post/blog-post-titanic.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installing Kaggle\n",
    "\n",
    "Getting ready for the Kaggle competition requires registering for the competition (a few clicks on the kaggle website), and installing kaggle on your local machine. The following is based on the [Live-Coding Session 7](https://youtu.be/cagqUrHMDJ0) and the related [official topic in the forums](https://forums.fast.ai/t/live-coding-7/96811).\n",
    "\n",
    "The first step is to install kaggle:\n",
    "\n",
    "```bash\n",
    "pip install --user kaggle\n",
    "```\n",
    "\n",
    "As a result, the following warning is displayed: `The script kaggle is installed in '/home/<your user>/.local/bin' which is not on PATH.` This means that the you need to add the path to the `PATH`-variable. This is done by adding the following line to the `.bashrc`-file and restarting the terminal:\n",
    "\n",
    "```bash\n",
    "PATH=~/.local/bin:$PATH\n",
    "```\n",
    "\n",
    "> Note: To display the current `PATH`-variable use: `echo $PATH`\n",
    "\n",
    "As a result, typing the `kaggle`-command on the command line works, but the next error shows up (as expected):\n",
    "`OSError: Could not find kaggle.json. Make sure it's located in /home/chrwittm/.kaggle. Or use the environment method.`\n",
    "\n",
    "This means that you cannot authorize against the kaggle platform. To solve this, download your personal `kaggle.json`\n",
    "On the kaggle website, navigate to: \"Account\" and click on \"Create New API Token\". As a result, the `kaggle.json` is downloaded.\n",
    "\n",
    "Copy the `kaggle.json`-file into the `.kaggle`-directory in your home directory.\n",
    "\n",
    "Typing the `kaggle`-command on the command line gives you the final clue as to what is missing:\n",
    "`Your Kaggle API key is readable by other users on this system! To fix this, you can run 'chmod 600 /home/chrwittm/.kaggle/kaggle.json'`\n",
    "\n",
    "Therefore, type: \n",
    "\n",
    "```bash\n",
    "chmod 600 /home/<your user>/.kaggle/kaggle.json\n",
    "```\n",
    "\n",
    "Typing the `kaggle`-command on the command line again confirms: We are in business :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Downloading the dataset\n",
    "\n",
    "To download the dataset, run the following command (which you can also find on the kaggle website): \n",
    "\n",
    "```bash\n",
    "kaggle competitions download -c titanic\n",
    "```\n",
    "\n",
    "As a result, the file `titanic.zip` is downloaded.\n",
    "\n",
    "To unzip type:\n",
    "\n",
    "```bash\n",
    "unzip titanic.zip\n",
    "```\n",
    "\n",
    "Doing this for the first time, this resulted in an error: `/bin/bash: unzip: command not found`\n",
    "\n",
    "To install zip and unzip, type:\n",
    "\n",
    "```bash\n",
    "sudo apt-get install zip\n",
    "sudo apt-get install unzip\n",
    "```\n",
    "\n",
    "As a result, unzipping works, and we have a dataset to work with :)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing a Fast.ai Tabular Learner\n",
    "\n",
    "The goal was not to create a perfect submission, but to simply train a model as fast as possible to\n",
    "\n",
    "* get a baseline\n",
    "* to get to know how a kaggle competition works (remember, this is my first one)\n",
    "\n",
    "Therefore, I created a dataloaders as shown in [lesson 1](https://youtu.be/8SF_h3xF3cE?t=3513) or [in the docs](https://docs.fast.ai/examples/app_examples.html#tabular) by sorting the variables into categorical or continuos one, excluding irrelevant ones).\n",
    "\n",
    "> Note 1: In this blog post, I am presenting the steps in a fast-forward way, here is the original [notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/titanic/titanic1/titanic1.ipynb).\n",
    "\n",
    "> Note 2: When writing this up, I was not able to 100% re-produce the same results, but basically this is how the story went."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.tabular.all import *\n",
    "\n",
    "path = \".\"\n",
    "\n",
    "dls = TabularDataLoaders.from_csv('train.csv', path=path, y_names=\"Survived\",\n",
    "    cat_names = ['Pclass', 'Sex', 'SibSp', 'Parch', 'Embarked'],\n",
    "    cont_names = ['Age', 'Fare'],\n",
    "    procs = [Categorify, FillMissing, Normalize])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can train a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.548652</td>\n",
       "      <td>0.315984</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.454461</td>\n",
       "      <td>0.325496</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.373511</td>\n",
       "      <td>0.289948</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.319270</td>\n",
       "      <td>0.251090</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.280473</td>\n",
       "      <td>0.196879</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.249269</td>\n",
       "      <td>0.173640</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.225535</td>\n",
       "      <td>0.152192</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.207350</td>\n",
       "      <td>0.141283</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.192223</td>\n",
       "      <td>0.137462</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.180697</td>\n",
       "      <td>0.137344</td>\n",
       "      <td>0.640449</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn = tabular_learner(dls, metrics=accuracy)\n",
    "learn.fit_one_cycle(10) #change this variable for more/less training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With this learner, we can make the predictions on the test-dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "    /* Turns off some styling */\n",
       "    progress {\n",
       "        /* gets rid of default border in Firefox and Opera. */\n",
       "        border: none;\n",
       "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
       "        background-size: auto;\n",
       "    }\n",
       "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
       "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
       "    }\n",
       "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
       "        background: #F44336;\n",
       "    }\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Survived_pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>Kelly, Mr. James</td>\n",
       "      <td>male</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>330911</td>\n",
       "      <td>7.8292</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>0.064765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>Wilkes, Mrs. James (Ellen Needs)</td>\n",
       "      <td>female</td>\n",
       "      <td>47.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>363272</td>\n",
       "      <td>7.0000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.454887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>Myles, Mr. Thomas Francis</td>\n",
       "      <td>male</td>\n",
       "      <td>62.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>240276</td>\n",
       "      <td>9.6875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Q</td>\n",
       "      <td>-0.025921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>Wirz, Mr. Albert</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>315154</td>\n",
       "      <td>8.6625</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>-0.015690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>Hirvonen, Mrs. Alexander (Helga E Lindqvist)</td>\n",
       "      <td>female</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3101298</td>\n",
       "      <td>12.2875</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "      <td>0.508172</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass                                          Name     Sex  \\\n",
       "0          892       3                              Kelly, Mr. James    male   \n",
       "1          893       3              Wilkes, Mrs. James (Ellen Needs)  female   \n",
       "2          894       2                     Myles, Mr. Thomas Francis    male   \n",
       "3          895       3                              Wirz, Mr. Albert    male   \n",
       "4          896       3  Hirvonen, Mrs. Alexander (Helga E Lindqvist)  female   \n",
       "\n",
       "    Age  SibSp  Parch   Ticket     Fare Cabin Embarked  Survived_pred  \n",
       "0  34.5      0      0   330911   7.8292   NaN        Q       0.064765  \n",
       "1  47.0      1      0   363272   7.0000   NaN        S       0.454887  \n",
       "2  62.0      0      0   240276   9.6875   NaN        Q      -0.025921  \n",
       "3  27.0      0      0   315154   8.6625   NaN        S      -0.015690  \n",
       "4  22.0      1      1  3101298  12.2875   NaN        S       0.508172  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = pd.read_csv(\"test.csv\")\n",
    "\n",
    "# replacing null values with 0\n",
    "test['Fare'] = test['Fare'].fillna(0)\n",
    "\n",
    "# create Predictions as suggested here:\n",
    "# https://forums.fast.ai/t/tabular-learner-prediction-using-data-frame/90534/2\n",
    "test_dl = learn.dls.test_dl(test)\n",
    "preds, _ = learn.get_preds(dl=test_dl)\n",
    "\n",
    "test['Survived_pred'] = preds.squeeze()\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interpreting the values in column `Survived_pred` is important, because we need to turn these values into `0` and `1` for the submission. The submission file should only have the columns `PassengerId` and `Survived`. For the first submission, I did not worry about it too much and simply picked a value `0.5`. (Let's come back to that a little later)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.5 #change this variable for more/less training\n",
    "test['Survived'] = [ 1 if element > threshold else 0 for element in preds.squeeze()]\n",
    "\n",
    "submission1 = test[['PassengerId', 'Survived']]\n",
    "submission1.to_csv('submission1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I uploaded the results, and they were better then random ;) - **Score 0.73923**\n",
    "\n",
    "![](first_submission.png)\n",
    "\n",
    "The score is not great, but the whole point was to get a baseline as quickly as possible, and to \"play the whole kaggle game\". Actually, the fact that I produced this result in about 1-2 hours felt pretty good :).\n",
    "\n",
    "> Note: Running this notebook, I got a score of 0.75119, I am not sure, what caused the difference... but better is always good ;)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So how can we improve the score? More training, interpreting the results differently? As it turns out: Both.\n",
    "\n",
    "Let's look at the distribution of `Survived_pred`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test.Survived_pred.hist();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As it turned out, setting my threshold to `0.6` created a better result: **Score: 0.74162**. (this I could not reproduce with this notebook while writing up the blog post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also more training, produced better results, running for 50 cycles, resulted in a lower loss and a better result. Training with 50 cycles and threshold `0.7`, this was the result: **Score: 0.76794** (with this notebook 0.77033)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So there is some randomness when training, and it is important to properly interpret the results. Getting about 77% right with this simple approach is not to bad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Re-Implemenmting the Excel Model\n",
    "\n",
    "After the quick win with Fast.AI, I decided to re-implement what Jeremy did in the Excel in [video lecture 3](https://www.youtube.com/watch?v=hBBOjCiFcuo&list=PLfYUBJiXbdtSvpQjSnJJ_PmDQB_VyT5iU&index=3&t=3862s) to predict the survivors. Let's see how it performs against the Fast.AI tabular learner.\n",
    "\n",
    "Since that involved quite a bit of code, let me simply link to [notebook](https://github.com/chrwittm/FastAI2022/blob/main/lesson03/titanic/titanic3/titanic3.ipynb) and discuss the learnings / results.\n",
    "\n",
    "As it turned out:\n",
    "\n",
    "* I had to do a bit of data cleansing.\n",
    "* The feature engineering took some time which taught me some general python lessons.\n",
    "* Implementing the optimizer was a nice exercise, revisiting [gradient descent](https://chrwittm.github.io/posts/2022-10-13-visualizing-gradient-descent-in-3d/) and [matrix multiplication](https://chrwittm.github.io/posts/2022-10-28-matrix-multiplication/), and doing some hands-on work with tensors.\n",
    "\n",
    "The first model with just one layer scored **0.75837**, even better than the my Fast.AI baseline, but not quite as good as the optimized version.\n",
    "\n",
    "The next iteration with 2 and 3 layers scored better:\n",
    "\n",
    "* **Score: 0.77033** (2-layers)\n",
    "* **Score: 0.77272** (3-layers)\n",
    "\n",
    "![](score077272.png)\n",
    "\n",
    "This was quite surprising: The self-written algorithm is better than the Fast.AI one, any ideas why that would be?\n",
    "\n",
    "Nonetheless, it seems to hit a ceiling at 77%, and it would make sense to dive deeper into tabular data, but that is for another time. My goal was not to optimize the competition result, but to participate in my first kaggle competition, and to re-visit the topic of gradient descent and matrix multiplication. I will most likely return to this dataset/challenge in the future.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "d9da906b64701e68312bc07fbc15a3a13814f930718c2c6b0e41a29d035806a3"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
